"""250515_ìœ„í—˜ì„±í‰ê°€ ì²´ì¸"""

from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnablePassthrough

from schemas import RiskAssessmentInput, RiskAssessmentOutput, risk_assessment_map
from models import ChainBase
from utils import get_logger, print_return


logger = get_logger(__name__)



class ProbabilityImpactRatingV1(ChainBase):
    def chain_call(self, model, embeddings):
        self.model = model
        self.embeddings = embeddings

        # Output Configuration
        structured_output = self.model.with_structured_output(RiskAssessmentOutput)

        # Retrieval
        reference_retriever = self.faiss_retrieval(file_name="faiss_K+S+O_Openai_v3")
        
        # Prompt
        self.prompt = "cy_rma_v4"
        def make_template(data):
            _prompt = [
                ("system", self.prompt["system"]),
                ("user", self.prompt["user"].format(
                    process_major_category=data["process_major_category"],
                    process_sub_category=data["process_sub_category"],
                    equipment= data["equipment"],
                    material= data["material"],
                    task_description= data["task_description"],
                    # count=data["count"],
                    reference=data["reference"],
                ))
            ]
            for _image in data["site_image"]:
                _prompt.append(
                    HumanMessage(
                        content=[
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": _image
                                },
                            }
                        ]
                    )
                )
            prompt_template = self.template_call("chat", _prompt)
            logger.debug(f"ğŸ”¹ {_prompt = }")
            logger.debug(f"ğŸ”¹ {prompt_template = }")
            return prompt_template
        
        def find_risks_from_image(images):
            _prompt = [
                ("system", "ì‚¬ì§„ì—ì„œ ìœ í•´ ìœ„í—˜ìš”ì¸ì„ **í•œêµ­ì–´**ë¡œ ì‹ë³„í•˜ì‹­ì‹œì˜¤. ì‚¬ì§„ì´ ì—†ë‹¤ë©´ 'ì‚¬ì§„ ì—†ìŒ'ì´ë¼ê³  ë‹µí•˜ì‹­ì‹œì˜¤."),
            ]
            for _image in images:
                _prompt.append(
                    HumanMessage(
                        content=[
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": _image
                                },
                            }
                        ]
                    )
                )
            retriever_prompt = self.template_call("chat", _prompt)
            logger.debug(f"ğŸ”¹ {_prompt = }")
            logger.debug(f"ğŸ”¹ {retriever_prompt = }")
            return retriever_prompt

        from typing import List
        from pydantic import BaseModel, Field
        class RetrievalOutput(BaseModel):
            risk_items: List[str] = Field(description="ì‚¬ì§„ ì† ìœ„í—˜ìš”ì¸ ëª©ë¡")
        
        def call_merge_risks():
            @print_return
            def merge_risks(args: RetrievalOutput):
                merged_risks = "\n- ".join(args.risk_items)
                logger.debug(f"ğŸ”¹ merge_risks: {args = }, {merged_risks = }")
                return merged_risks
            return merge_risks

        def call_merge_dicts_as_str():
            @print_return
            def merge_dicts_as_str(kwargs):
                logger.debug(f"ğŸ”¹ merge_dicts_as_str: {kwargs = }")
                return "\n".join([f"{k}: {v}" for k, v in kwargs.items()])
            return merge_dicts_as_str

        # Identify Risks from Image
        from_image_chain = (
            lambda x: find_risks_from_image(x["site_image"]) 
            | RunnablePassthrough() 
            | self.printer 
            | self.model.with_structured_output(RetrievalOutput) 
            | self.printer 
            | call_merge_risks()
        )

        # Reference Retriever
        reference_chain_head = self.parallel_init({
            "ìœ„í—˜ ìš”ì¸": from_image_chain,
            "ì‘ì—… ì •ë³´": self.get_dict2str(mapping=risk_assessment_map),
        })
        reference_chain_tail = (
            self.printer
            | RunnablePassthrough()
            | call_merge_dicts_as_str()
            | self.printer
            | reference_retriever
            | self.format_docs
        )
        reference_chain = reference_chain_head | reference_chain_tail

        # Input Configuration
        chain_init = self.parallel_init({
            "site_image": lambda x: x["site_image"],
            "process_major_category": lambda x: x["process_major_category"],
            "process_sub_category": lambda x: x["process_sub_category"],
            "equipment":  lambda x: x["equipment"],
            "material":   lambda x: x["material"],
            "task_description": lambda x: x["task_description"],
            # "count":      lambda x: x["count"],
            "reference": reference_chain
        })

        # Final Prompt Chain
        prompt_chain = lambda x: make_template(x) | RunnablePassthrough()

        # Final Chain
        chain = chain_init | self.printer | prompt_chain | self.printer | structured_output | self.printer
        return chain
    
    def _register_chain(self, **kwargs):
        incorporation = kwargs.get("incorporation")
        model = kwargs.get("model")
        embeddings = kwargs.get("embeddings")

        logger.debug(f"ğŸ”¹ {incorporation = }, {model = }, {embeddings = }")

        untag = lambda x: x.split(":")[0] if ":" in x else x
        
        self.chain = {
            "chain": self.chain_call(
                model=f"{incorporation}/{model}",
                embeddings=f"{incorporation}/{embeddings}"
            ),
            "path": f"/{untag(model)}/pi-ratings",
            "input_type": RiskAssessmentInput,
        }
        
        

__all__ = ["ProbabilityImpactRatingV1"]


if __name__ == "__main__":
    from utils import pretty_print_risk_evaluation_v2

    result = ProbabilityImpactRatingV1().chain_call(
        model="openai/gpt-4o",
        embeddings="openai/text-embedding-ada-002"
    ).invoke({
        "process_major_category": "ê¸°ì´ˆíŒŒì¼ì‘ì—…",
        "process_sub_category": "ê¸°ì´ˆíŒŒì¼ ìì¬, ì¥ë¹„ë°˜ì…, ìš´ë°˜, ë³´ê´€",
        "equipment": "ì§€ê²Œì°¨",
        "material": "",
        "task_description": "ì´ˆê³µì‚¬ ë‹¨ê³„ì˜ ì§„í–‰ì— ë”°ë¼ ê¸°ì´ˆíŒŒì¼ ë°˜ì… ë° ì ì¹˜ì‘ì—…, íŒŒì¼ ì„ í–‰ ì •ë ¬, íŒŒì¼ ë°•ê¸° ì¤€ë¹„ì‘ì—…ì´ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤. ì˜¤ì „ ì¤‘ì—ëŠ” ê¸°ì´ˆíŒŒì¼ ìì¬ê°€ í˜„ì¥ìœ¼ë¡œ ì¶”ê°€ ë°˜ì…ë˜ë©°, íŠ¸ë ˆì¼ëŸ¬ 2ëŒ€ ë¶„ëŸ‰ì˜ íŒŒì¼ì´ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤. í•´ë‹¹ ìì¬ëŠ” 5í†¤ ì§€ê²Œì°¨ë¥¼ ì´ìš©í•˜ì—¬ í•˜ì°¨ í›„ ì§€ì •ëœ íŒŒì¼ ì ì¹˜ì¥ì†Œë¡œ ìš´ë°˜ ë° ì •ë¦¬í•˜ê²Œ ë˜ë©°, ì§€ê²Œì°¨ ìš´ì „ì› 1ëª…ê³¼ ë³´ì¡°ì¸ë ¥ 2ëª…ì´ íˆ¬ì…ë©ë‹ˆë‹¤.
        íŒŒì¼ ë°˜ì… ë° ì •ë¦¬ì‘ì—…ì´ ì™„ë£Œëœ ì´í›„, ì˜¤í›„ì—ëŠ” ë°•ê¸°ì‘ì—…ì„ ìœ„í•œ íŒŒì¼ ì •ë ¬ ë° ìœ„ì¹˜ í‘œì‹œ ì‘ì—…ì´ ì§„í–‰ë©ë‹ˆë‹¤. ì¸¡ëŸ‰íŒ€ 2ì¸ì´ ë ˆë²¨ê¸°ì™€ ê´‘íŒŒê¸°ë¥¼ í™œìš©í•˜ì—¬ íŒŒì¼ ì¤‘ì‹¬ ìœ„ì¹˜ë¥¼ ì¬í™•ì¸í•˜ê³ , ë§ˆí‚¹ ë° ìˆ˜ì§ë„ ê¸°ì¤€ì„  ì„¤ì •ì„ ì™„ë£Œí•  ì˜ˆì •ì…ë‹ˆë‹¤. ë™ì‹œì—, í˜„ì¥ ë‚´ íŒŒì¼ë“œë¼ì´ë²„ ì„¤ì¹˜ì‘ì—…ì´ ì§„í–‰ë˜ë©°, 80í†¤ê¸‰ í¬ë¡¤ëŸ¬ í¬ë ˆì¸ 1ëŒ€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ë¹„ë¥¼ ì‘ì—…ìœ„ì¹˜ë¡œ ì´ë™ ë° ì„¸íŒ…í•˜ê²Œ ë©ë‹ˆë‹¤. í¬ë ˆì¸ ìš´ì „ì› 1ëª…ê³¼ ì¥ë¹„ ë³´ì¡° 2ëª…, ì‘ì—…ê°ë…ì 1ëª…ì´ ë°°ì¹˜ë©ë‹ˆë‹¤.
        ê¸°ì´ˆíŒŒì¼ ë°•ê¸° ì‘ì—…ì€ ì˜ˆë¹„íŒŒì¼ 3ë³¸ì— ëŒ€í•´ ì‹œí—˜íƒ€ì… í˜•ì‹ìœ¼ë¡œ ì§„í–‰ë˜ë©°, ì˜¤í›„ ì¤‘í›„ë°˜ë¶€í„° ì‹œì‘í•˜ì—¬ ì¼ëª° ì „ê¹Œì§€ 1~2ë³¸ì˜ íŒŒì¼ì„ ì‹œê³µí•  ê³„íšì…ë‹ˆë‹¤. íƒ€ê²©ì€ ë””ì ¤í•´ë¨¸ ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë˜ë©°, íŒŒì¼ê¸¸ì´ì™€ ì§€ë°˜ì¡°ê±´ì— ë”°ë¼ ê´€ì…ì €í•­ ì¸¡ì •ì„ ë³‘í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤. íŒŒì¼ ì‹œê³µíŒ€ 4ëª…ì´ íˆ¬ì…ë˜ë©°, íŒŒì¼ ìœ ì§€ ë° ìˆ˜ì§ë„ í™•ì¸ì„ ìœ„í•œ ì‘ì—…ìê°€ ë³„ë„ë¡œ ë°°ì¹˜ë©ë‹ˆë‹¤.
        ì „ë°˜ì ìœ¼ë¡œ ê¸ˆì¼ì€ ì¥ë¹„ ë° ìì¬ì˜ ì •ë¦¬, ì‹œí—˜íƒ€ì…ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ì´ˆíŒŒì¼ ê³µì •ì˜ ì´ˆê¸°ë‹¨ê³„ë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ë‚ ë¡œ, ê° ê³µì •ê°„ ì—°ê³„ì„±ê³¼ ì¥ë¹„ ì´ë™ íš¨ìœ¨ì„±ì„ ê³ ë ¤í•œ ì‘ì—… ë°°ì¹˜ê°€ ì¤‘ì ì ìœ¼ë¡œ ì´ë¤„ì§ˆ ì˜ˆì •ì…ë‹ˆë‹¤.",
        "site_image": ["https://lh6.googleusercontent.com/proxy/YQLmuoGq5msa3_sCnE5CNZRTP53MoQ9S_XnrzkxKHjJdZbhG4CqAHVzknEcw15x35pLc5dOD3AC0uaEDqiMFbJcY1OkNQ8jrVNW39BWR"],
        "count": "10"
    })

    for k, v in dict(result).items():
        if k.strip().startswith("ìœ„í—˜ì„±í‰ê°€í‘œ"):
            logger.info(f"- {k}:")
            for i in v:
                logger.info(f"  - {i}")
        else:
            logger.info(f"- {k}: {v}")

    pretty_print_risk_evaluation_v2(result.ê³µì¢…, 
                                    result.ê³µì •, 
                                    result.ì‘ì—…ëª…, 
                                    result.ìœ„í—˜ì„±í‰ê°€í‘œ, 
                                    result.ê¸°íƒ€)
