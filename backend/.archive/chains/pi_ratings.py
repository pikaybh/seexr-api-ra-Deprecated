"""250515_ìœ„í—˜ì„±í‰ê°€ ì²´ì¸"""


from langchain_core.runnables import RunnablePassthrough

from schemas import RiskAssessmentInput, RiskAssessmentOutput, risk_assessment_map
from models import ChainBase
from utils import get_logger, print_return

logger = get_logger(__name__)



class ProbabilityImpactRatingV1(ChainBase):
    def chain_call(self, model, embeddings):
        self.model = model
        self.embeddings = embeddings

        # Output Configuration
        structured_output = self.model.with_structured_output(RiskAssessmentOutput)

        # Retrieval
        reference_retriever = self.faiss_retrieval(file_name="faiss_K+S+O_Openai_v3")
        
        from langchain_core.messages import HumanMessage
        # Prompt
        self.prompt = "cy_rma_v3"
        def make_template(data):
            _prompt = [
                ("system", self.prompt["system"]),
                ("user", self.prompt["user"].format(
                    process_major_category=data["process_major_category"],
                    process_sub_category=data["process_sub_category"],
                    equipment= data["equipment"],
                    material= data["material"],
                    task_description= data["task_description"],
                    # count=data["count"],
                    reference=data["reference"],
                ))
            ]
            for _image in data["site_image"]:
                _prompt.append(
                    HumanMessage(
                        content=[
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": _image
                                },
                            }
                        ]
                    )
                )
            prompt_template = self.template_call("chat", _prompt)
            print(f"ğŸ”¹ {_prompt = }")
            print(f"ğŸ”¹ {prompt_template = }")
            return prompt_template
        
        def find_risks_from_image(images):
            _prompt = [
                ("system", "ì‚¬ì§„ì—ì„œ ìœ í•´ ìœ„í—˜ìš”ì¸ì„ **í•œêµ­ì–´**ë¡œ ì‹ë³„í•˜ì‹­ì‹œì˜¤. ì‚¬ì§„ì´ ì—†ë‹¤ë©´ 'ì‚¬ì§„ ì—†ìŒ'ì´ë¼ê³  ë‹µí•˜ì‹­ì‹œì˜¤."),
            ]
            for _image in images:
                _prompt.append(
                    HumanMessage(
                        content=[
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": _image
                                },
                            }
                        ]
                    )
                )
            retriever_prompt = self.template_call("chat", _prompt)
            print(f"ğŸ”¹ {__spec__}: {retriever_prompt = }")

            return retriever_prompt

        from typing import List
        from pydantic import BaseModel, Field
        class RetrievalOutput(BaseModel):
            risk_items: List[str] = Field(description="ì‚¬ì§„ ì† ìœ„í—˜ìš”ì¸ ëª©ë¡")
        
        @print_return
        def merge_risks(args: RetrievalOutput):
            merged_risks = "\n- ".join(args.risk_items)
            print(f"ğŸ”¹ merge_risks: {args = }, {merged_risks = }")
            return merged_risks

        from langchain_core.runnables import RunnableParallel, RunnableLambda

        def merge_dicts_as_str_shell():
            @print_return
            def merge_dicts_as_str(kwargs):
                print(f"ğŸ”¹ merge_dicts_as_str: {kwargs = }")
                return "\n".join([f"{k}: {v}" for k, v in kwargs.items()])
            return merge_dicts_as_str

        # Input Configuration
        chain_init = self.parallel_init({
            "site_image": lambda x: x["site_image"],
            "process_major_category": lambda x: x["process_major_category"],
            "process_sub_category": lambda x: x["process_sub_category"],
            "equipment":  lambda x: x["equipment"],
            "material":   lambda x: x["material"],
            "task_description": lambda x: x["task_description"],
            # "count":      lambda x: x["count"],
            "reference": self.parallel_init({
                "ì‚¬ì§„ ì† ìœ„í—˜ìš”ì¸ ëª©ë¡": lambda x: find_risks_from_image(x["site_image"]) | RunnablePassthrough() | self.printer | self.model.with_structured_output(RetrievalOutput) | self.printer | merge_risks,
                "ì‘ì—… ì •ë³´": self.get_dict2str(mapping=risk_assessment_map),
            })
            | self.printer
            | RunnablePassthrough()
            | merge_dicts_as_str_shell()
            | self.printer
            # | RunnablePassthrough()
            | reference_retriever
            | self.format_docs
        })

        # Final Chain
        chain = chain_init | self.printer | (lambda x: make_template(x) | RunnablePassthrough()) | self.printer | structured_output | self.printer
        return chain
    
    def _register_chain(self, **kwargs):
        incorporation = kwargs.get("incorporation")
        model = kwargs.get("model")
        embeddings = kwargs.get("embeddings")
        print(f"ğŸ”¹ {__spec__}: {incorporation = }, {model = }, {embeddings = }")
        
        self.chain = {
            "chain": self.chain_call(
                model=f"{incorporation}/{model}",
                embeddings=f"{incorporation}/{embeddings}"
            ),
            "path": f"/{model}/pi-ratings",
            "input_type": RiskAssessmentInput,
        }
        
        

__all__ = ["ProbabilityImpactRatingV1"]


if __name__ == "__main__":
    from utils import pretty_print_risk_evaluation_v2

    result = ProbabilityImpactRatingV1().chain_call(
        model="openai/gpt-4o",
        embeddings="openai/text-embedding-ada-002"
    ).invoke({
        "process_major_category": "í† ê³µì‘ì—…",
        "process_sub_category": "",
        "equipment": "ì†Œí˜• í¬ë ˆì¸, ì§€ê²Œì°¨, êµ´ì‚­ê¸°",
        "material": "í† ì‚¬",
        "task_description": "ê¸ˆì¼ ê³„íšì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. í† ê³µ ì‘ì—…ìœ¼ë¡œëŠ” ë¦¬í•‘ì•” ì ˆì·¨ì™€ ìƒì°¨, ë…¹ì§€ëŒ€ ì„±í† , ì™¸ë¶€ í† ì‚¬ ë°˜ì… ë° ë²•ë©´ ì ˆì·¨ê°€ í¬í•¨ë˜ë©°, êµ¬ì¡°ë¬¼ ê³µì‚¬ë¡œëŠ” íŒ¨ë„ ë° ë¸”ë¡ ì„¤ì¹˜ì™€ ë‚´ë¶€ ê±°í‘¸ì§‘ ì„¤ì¹˜ê°€ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¶€ëŒ€ê³µì€ ì² ê±°ì™€ ì²œê³µ, ë°œíŒŒ ì‘ì—…ì´ ìˆìŠµë‹ˆë‹¤.",
        "site_image": ["https://lh3.googleusercontent.com/proxy/SmpTSrfjKevfYs-EbOwgr6sic6909ehrObyyH15Tpgk8Qgq30iW-ERO8ggkSledzSEQwiLAvGGproVw6GoCgec-tt4MOtzVCsCkTkFPGEWhmjVuJ"],
        "count": "10"
    })

    for k, v in dict(result).items():
        if k.strip().startswith("ìœ„í—˜ì„±í‰ê°€í‘œ"):
            logger.info(f"- {k}:")
            for i in v:
                logger.info(f"  - {i}")
        else:
            logger.info(f"- {k}: {v}")

    pretty_print_risk_evaluation_v2(
        result.ê³µì¢…, result.ê³µì •, result.ì‘ì—…ëª…, result.ìœ„í—˜ì„±í‰ê°€í‘œ, result.ê¸°íƒ€
    )
